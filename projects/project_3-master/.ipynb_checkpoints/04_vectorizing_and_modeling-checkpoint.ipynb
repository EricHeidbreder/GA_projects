{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vecorization and Modeling out data\n",
    "\n",
    "In this notebook, I'll be creating `Pipelines` to help vectorize and model my data. I'll use `GridSearchCV` to iterate over parameters in my pipelines. The models I explore are Logistic Regression, Multinomial Naive Bayes, and Support Vector Classfication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "from my_functions import tokenize_and_stem\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = pd.read_csv('./data/reddit_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X and y values to be passed through train_test_split\n",
    "X = posts['selftext']\n",
    "y = posts['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=182, stratify=y) # our data is pretty close to even, but I still want to stratify just to be safe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a stop word list based on my EDA of words that aren't helpful\n",
    "stop_words = [\n",
    "    'https',\n",
    "    'com',\n",
    "    'www',\n",
    "    'amp',\n",
    "    'like',\n",
    "    'just',\n",
    "    'spotify',\n",
    "    'because',\n",
    "    'song',\n",
    "    'music',\n",
    "    'album',\n",
    "    'want',\n",
    "    'would',\n",
    "    'make',\n",
    "    'know',\n",
    "    'becau',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of custom stop words\n",
    "custom_sw = stopwords.words('english') + stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'processed_sw' (list)\n"
     ]
    }
   ],
   "source": [
    "# Processing my stop words in the same way I'll process my data\n",
    "processed_sw = tokenize_and_stem(' '.join(custom_sw))\n",
    "\n",
    "# Storing this for later use across Jupyter Notebooks\n",
    "%store processed_sw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's our baseline score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "poppunkers    0.500784\n",
       "punk          0.499216\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline score\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline score is about 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up and Running Pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting variables for the my eventual parameter grid for easy tuning\n",
    "max_df = [0.80]\n",
    "min_df = [0, 0.002]\n",
    "ngram_range = [(1, 2), (1, 1)]\n",
    "max_features = [4000]\n",
    "stop_words = [processed_sw, None]\n",
    "tokenizer = [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer and Naive Bayes\n",
    "pipe_cvec_nb = Pipeline([\n",
    "    ('cvec', CountVectorizer(tokenizer=tokenize_and_stem)),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Setting my parameters\n",
    "params_cvec_nb = {\n",
    "    'cvec__max_df' : max_df,\n",
    "    'cvec__min_df' : min_df,\n",
    "    'cvec__max_features' : max_features,\n",
    "    'cvec__ngram_range' : ngram_range,\n",
    "    'cvec__stop_words' : stop_words\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer and Logistic Regression\n",
    "pipe_cvec_lr = Pipeline([\n",
    "    ('cvec', CountVectorizer(tokenizer=tokenize_and_stem)),\n",
    "    ('lr', LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "params_cvec_lr = {\n",
    "    'cvec__max_df' : max_df,\n",
    "    'cvec__min_df' : min_df,\n",
    "    'cvec__max_features' : max_features,\n",
    "    'cvec__ngram_range' : ngram_range,\n",
    "    'cvec__stop_words' : stop_words\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tfidf Vectorizer and SVC\n",
    "pipe_tvec_svc = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('svc', SVC(degree=2, kernel='poly'))\n",
    "])\n",
    "\n",
    "params_tvec_svc = {\n",
    "    'tvec__max_df' : max_df,\n",
    "    'tvec__min_df' : min_df,\n",
    "    'tvec__max_features' : max_features,\n",
    "    'tvec__ngram_range' : ngram_range,\n",
    "    'svc__C' : [0.789495]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_1 = GridSearchCV(pipe_cvec_nb,\n",
    "                         param_grid=params_cvec_nb,\n",
    "                         cv=5,\n",
    "                         n_jobs = 12,\n",
    "                         verbose=2)\n",
    "\n",
    "gs_3 = GridSearchCV(pipe_cvec_lr,\n",
    "                         param_grid=params_cvec_lr,\n",
    "                         cv=5,\n",
    "                         n_jobs = 12,\n",
    "                         verbose=2)\n",
    "\n",
    "gs_4 = GridSearchCV(pipe_tvec_svc,\n",
    "                         param_grid=params_tvec_svc,\n",
    "                         cv=5,\n",
    "                         n_jobs = 12,\n",
    "                         verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Commented out so the .csv doesn't get overwritten\n",
    "# model_params = {}\n",
    "# count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment if you really want to run this GridSearch again, it will take awhile\n",
    "# gs_1.fit(X_train, y_train)\n",
    "# gs_3.fit(X_train, y_train)\n",
    "# gs_4.fit(X_train, y_train)\n",
    "\n",
    "# # Create a new dictionary entry with the vectorizer used in the GridSearch Pipeline\n",
    "# gs_1.best_params_['vectorizer'] = gs_1.estimator[0]\n",
    "# gs_3.best_params_['vectorizer'] = gs_3.estimator[0]\n",
    "# gs_4.best_params_['vectorizer'] = gs_4.estimator[0]\n",
    "\n",
    "# # Create a new dictionary entry with the model used in the GridSearch Pipeline\n",
    "# gs_1.best_params_['model'] = gs_1.estimator[1]\n",
    "# gs_3.best_params_['model'] = gs_3.estimator[1]\n",
    "# gs_4.best_params_['model'] = gs_4.estimator[1]\n",
    "\n",
    "# # Create a new dictionary entry with the train score from the GridSearch\n",
    "# gs_1.best_params_['train_score'] = gs_1.best_score_\n",
    "# gs_3.best_params_['train_score'] = gs_3.best_score_\n",
    "# gs_4.best_params_['train_score'] = gs_4.best_score_\n",
    "\n",
    "# # Create a new dictionary entry with the test score from the GridSearch\n",
    "# gs_1.best_params_['test_score'] = gs_1.score(X_test, y_test)\n",
    "# gs_3.best_params_['test_score'] = gs_3.score(X_test, y_test)\n",
    "# gs_4.best_params_['test_score'] = gs_4.score(X_test, y_test)\n",
    "\n",
    "# # Add each of these entries to the list\n",
    "# count += 1\n",
    "# model_params[f'model_{count}'] = gs_1.best_params_\n",
    "# count += 1\n",
    "# model_params[f'model_{count}'] = gs_3.best_params_\n",
    "# count += 1\n",
    "# model_params[f'model_{count}'] = gs_4.best_params_\n",
    "\n",
    "# # Create a DataFrame from the dictionary we created above\n",
    "# model_df = pd.DataFrame.from_dict(model_params, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to store model is commented out so it doesn't get overwritten\n",
    "# model_df.to_csv('./data/gs_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.read_csv('./data/gs_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.index.name = 'Test Number'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cvec__max_df</th>\n",
       "      <th>cvec__max_features</th>\n",
       "      <th>cvec__min_df</th>\n",
       "      <th>cvec__ngram_range</th>\n",
       "      <th>cvec__stop_words</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>svc__C</th>\n",
       "      <th>tvec__max_df</th>\n",
       "      <th>tvec__max_features</th>\n",
       "      <th>tvec__min_df</th>\n",
       "      <th>tvec__ngram_range</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.95</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>['i', 'me', 'my', 'myself', 'we', 'our', 'our'...</td>\n",
       "      <td>CountVectorizer(tokenizer=&lt;function tokenize_a...</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.811783</td>\n",
       "      <td>0.834901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.95</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>['i', 'me', 'my', 'myself', 'we', 'our', 'our'...</td>\n",
       "      <td>CountVectorizer(tokenizer=&lt;function tokenize_a...</td>\n",
       "      <td>LogisticRegression(max_iter=2000)</td>\n",
       "      <td>0.788779</td>\n",
       "      <td>0.830721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.99</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>['i', 'me', 'my', 'myself', 'we', 'our', 'our'...</td>\n",
       "      <td>CountVectorizer(tokenizer=&lt;function tokenize_a...</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.812131</td>\n",
       "      <td>0.832811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.99</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>['i', 'me', 'my', 'myself', 'we', 'our', 'our'...</td>\n",
       "      <td>CountVectorizer(tokenizer=&lt;function tokenize_a...</td>\n",
       "      <td>LogisticRegression(max_iter=2000)</td>\n",
       "      <td>0.787733</td>\n",
       "      <td>0.831766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.80</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>['i', 'me', 'my', 'myself', 'we', 'our', 'our'...</td>\n",
       "      <td>CountVectorizer(tokenizer=&lt;function tokenize_a...</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.812131</td>\n",
       "      <td>0.832811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.80</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>['i', 'me', 'my', 'myself', 'we', 'our', 'our'...</td>\n",
       "      <td>CountVectorizer(tokenizer=&lt;function tokenize_a...</td>\n",
       "      <td>LogisticRegression(max_iter=2000)</td>\n",
       "      <td>0.787733</td>\n",
       "      <td>0.831766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>SVC(degree=2, kernel='poly')</td>\n",
       "      <td>0.793301</td>\n",
       "      <td>0.807732</td>\n",
       "      <td>0.789495</td>\n",
       "      <td>0.95</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>SVC(degree=2, kernel='poly')</td>\n",
       "      <td>0.793301</td>\n",
       "      <td>0.807732</td>\n",
       "      <td>0.789495</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>SVC(degree=2, kernel='poly')</td>\n",
       "      <td>0.793301</td>\n",
       "      <td>0.807732</td>\n",
       "      <td>0.789495</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cvec__max_df  cvec__max_features  cvec__min_df cvec__ngram_range  \\\n",
       "Test Number                                                                     \n",
       "0                    0.95              4000.0         0.001            (1, 2)   \n",
       "1                    0.95              4000.0         0.001            (1, 2)   \n",
       "2                    0.99              4000.0         0.000            (1, 2)   \n",
       "3                    0.99              4000.0         0.000            (1, 2)   \n",
       "4                    0.80              4000.0         0.000            (1, 2)   \n",
       "5                    0.80              4000.0         0.000            (1, 2)   \n",
       "6                     NaN                 NaN           NaN               NaN   \n",
       "7                     NaN                 NaN           NaN               NaN   \n",
       "8                     NaN                 NaN           NaN               NaN   \n",
       "\n",
       "                                              cvec__stop_words  \\\n",
       "Test Number                                                      \n",
       "0            ['i', 'me', 'my', 'myself', 'we', 'our', 'our'...   \n",
       "1            ['i', 'me', 'my', 'myself', 'we', 'our', 'our'...   \n",
       "2            ['i', 'me', 'my', 'myself', 'we', 'our', 'our'...   \n",
       "3            ['i', 'me', 'my', 'myself', 'we', 'our', 'our'...   \n",
       "4            ['i', 'me', 'my', 'myself', 'we', 'our', 'our'...   \n",
       "5            ['i', 'me', 'my', 'myself', 'we', 'our', 'our'...   \n",
       "6                                                          NaN   \n",
       "7                                                          NaN   \n",
       "8                                                          NaN   \n",
       "\n",
       "                                                    vectorizer  \\\n",
       "Test Number                                                      \n",
       "0            CountVectorizer(tokenizer=<function tokenize_a...   \n",
       "1            CountVectorizer(tokenizer=<function tokenize_a...   \n",
       "2            CountVectorizer(tokenizer=<function tokenize_a...   \n",
       "3            CountVectorizer(tokenizer=<function tokenize_a...   \n",
       "4            CountVectorizer(tokenizer=<function tokenize_a...   \n",
       "5            CountVectorizer(tokenizer=<function tokenize_a...   \n",
       "6                                            TfidfVectorizer()   \n",
       "7                                            TfidfVectorizer()   \n",
       "8                                            TfidfVectorizer()   \n",
       "\n",
       "                                         model  train_score  test_score  \\\n",
       "Test Number                                                               \n",
       "0                              MultinomialNB()     0.811783    0.834901   \n",
       "1            LogisticRegression(max_iter=2000)     0.788779    0.830721   \n",
       "2                              MultinomialNB()     0.812131    0.832811   \n",
       "3            LogisticRegression(max_iter=2000)     0.787733    0.831766   \n",
       "4                              MultinomialNB()     0.812131    0.832811   \n",
       "5            LogisticRegression(max_iter=2000)     0.787733    0.831766   \n",
       "6                 SVC(degree=2, kernel='poly')     0.793301    0.807732   \n",
       "7                 SVC(degree=2, kernel='poly')     0.793301    0.807732   \n",
       "8                 SVC(degree=2, kernel='poly')     0.793301    0.807732   \n",
       "\n",
       "               svc__C  tvec__max_df  tvec__max_features  tvec__min_df  \\\n",
       "Test Number                                                             \n",
       "0                 NaN           NaN                 NaN           NaN   \n",
       "1                 NaN           NaN                 NaN           NaN   \n",
       "2                 NaN           NaN                 NaN           NaN   \n",
       "3                 NaN           NaN                 NaN           NaN   \n",
       "4                 NaN           NaN                 NaN           NaN   \n",
       "5                 NaN           NaN                 NaN           NaN   \n",
       "6            0.789495          0.95              4000.0         0.002   \n",
       "7            0.789495          0.99              4000.0         0.002   \n",
       "8            0.789495          0.80              4000.0         0.002   \n",
       "\n",
       "            tvec__ngram_range  \n",
       "Test Number                    \n",
       "0                         NaN  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3                         NaN  \n",
       "4                         NaN  \n",
       "5                         NaN  \n",
       "6                      (1, 1)  \n",
       "7                      (1, 1)  \n",
       "8                      (1, 1)  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model names wouldn't sort properly until turned into strings\n",
    "model_df['model'] = model_df['model'].astype(str) \n",
    "\n",
    "# Sorting df by model name, verbose\n",
    "model_df.sort_values(by=['model', 'test_score']).to_csv('./data/verbose_sorted_gs_results.csv')\n",
    "\n",
    "# Sorting df by model name and selecting condensed features\n",
    "model_df.sort_values(by=['model', 'test_score'])[['model', 'cvec__ngram_range', 'tvec__ngram_range', 'train_score', 'test_score']].to_csv('./data/condensed_sorted_gs_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights from running GridSearchCV\n",
    "\n",
    "The tokenizer I built in the third notebook ended up only being helpful when running Pipelines with `CountVectorizer()`. Stop words were also only helpful for `CountVectorizer()` pipelines.\n",
    "\n",
    "Also, I originally had a CountVectorizer() --> SVC pipeline, but removed it because it was performing so poorly.\n",
    "\n",
    "Ultimately, I'm going with the **Naive Bayes model** as my production model because of its interpretability and performance, though the SVC model has less variance, it's uninterpretable and would be difficult to explain to a stakeholder who isn't familiar with statistical models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cvec__max_df                                                        0.8\n",
       "cvec__max_features                                                 4000\n",
       "cvec__min_df                                                          0\n",
       "cvec__ngram_range                                                (1, 2)\n",
       "cvec__stop_words      ['i', 'me', 'my', 'myself', 'we', 'our', 'our'...\n",
       "vectorizer            CountVectorizer(tokenizer=<function tokenize_a...\n",
       "model                                                   MultinomialNB()\n",
       "train_score                                                    0.812131\n",
       "test_score                                                     0.832811\n",
       "svc__C                                                              NaN\n",
       "tvec__max_df                                                        NaN\n",
       "tvec__max_features                                                  NaN\n",
       "tvec__min_df                                                        NaN\n",
       "tvec__ngram_range                                                   NaN\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.loc[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building my production model and prepping dataframes for conclusions\n",
    "\n",
    "Below, I'll instantiate and fit my production model and create some dataframes of results that I'll investigate further in my conclusions notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rebuilding my best scoring model\n",
    "cvec = CountVectorizer(\n",
    "    tokenizer=tokenize_and_stem,\n",
    "    max_df=0.99,\n",
    "    min_df=0,\n",
    "    max_features=4000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=processed_sw\n",
    ")\n",
    "\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Count Vectorizing my training and testing data\n",
    "X_train_cvec = cvec.fit_transform(X_train)\n",
    "X_test_cvec = cvec.transform(X_test)\n",
    "\n",
    "# Fitting my best scoring model\n",
    "nb.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81533101, 0.81010453, 0.82055749, 0.81010453, 0.82024433])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final cross val score of my production model\n",
    "cross_val_score(nb, X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.832810867293626"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final test score of my production model\n",
    "nb.score(X_test_cvec, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Probabilities Dataframe\n",
    "\n",
    "Now I want to create a dataframe that has the probabilities of an observation (post) being classified as belonging to the `poppunkers` or `punk` subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the probabilities that a post belongs to one class or the other\n",
    "probabilities = nb.predict_proba(X_test_cvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe of my results\n",
    "proba_df = pd.DataFrame(probabilities,\n",
    "                       columns=nb.classes_, # Getting class names\n",
    "                       index=X_test.index # Setting original index of X_train\n",
    "                       )\n",
    "\n",
    "proba_df['orig_post'] = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting so I can easily pull the top words for each subreddit.\n",
    "sorted_probas = proba_df.sort_values(by='poppunkers', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving this for later!\n",
    "sorted_probas.to_csv('./data/prod_model_sorted_probas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a word importance dataframe\n",
    "This dataframe will show how important a word was to our Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summing the columns in the X_test_cvec array, thanks John Vinyard from\n",
    "# Stack Overflow: https://stackoverflow.com/questions/13567345/how-to-calculate-the-sum-of-all-columns-of-a-2d-numpy-array-efficiently\n",
    "word_freq = X_test_cvec.toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame for word importance\n",
    "word_importance = pd.DataFrame(np.exp(nb.coef_.T), index=cvec.get_feature_names())\n",
    "word_importance.columns = ['coefficient']\n",
    "word_importance['testing_word_freq'] = word_freq\n",
    "\n",
    "# Let's sort this by the Coefficient\n",
    "word_importance_sorted = word_importance.sort_values(by='coefficient', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving this for later\n",
    "word_importance.to_csv('./data/word_importance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a dataframe of the predicted and true classes\n",
    "\n",
    "Now I want to create a dataframe of the original posts and their predicted and actual subreddits. I'll take a look at which posts we didn't classify correctly and see which words were used most in those posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting my y_preds\n",
    "y_preds = nb.predict(X_test_cvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(data={'predicted_subreddit' : y_preds,\n",
    "                                'actual_subreddit' : y_test.tolist(),\n",
    "                                'orig_post' : X_test\n",
    "                                },\n",
    "                           index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('./data/prod_model_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Next?\n",
    "\n",
    "Onward to the conclusions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
